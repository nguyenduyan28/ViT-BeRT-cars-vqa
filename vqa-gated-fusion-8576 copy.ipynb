{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-25T02:40:07.571150Z",
     "iopub.status.busy": "2025-04-25T02:40:07.570909Z",
     "iopub.status.idle": "2025-04-25T02:40:08.901401Z",
     "shell.execute_reply": "2025-04-25T02:40:08.900782Z",
     "shell.execute_reply.started": "2025-04-25T02:40:07.571121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:03:21.330498Z",
     "iopub.status.busy": "2025-05-16T08:03:21.329796Z",
     "iopub.status.idle": "2025-05-16T08:03:46.159891Z",
     "shell.execute_reply": "2025-05-16T08:03:46.159051Z",
     "shell.execute_reply.started": "2025-05-16T08:03:21.330471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 08:03:35.375840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747382615.563754      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747382615.617757      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import ViTModel, BertModel, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from huggingface_hub import HfApi, login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:04:08.104949Z",
     "iopub.status.busy": "2025-05-16T08:04:08.104302Z",
     "iopub.status.idle": "2025-05-16T08:04:11.496335Z",
     "shell.execute_reply": "2025-05-16T08:04:11.495795Z",
     "shell.execute_reply.started": "2025-05-16T08:04:08.104924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab2f8f1edba4ac7b48c8bd7167367f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a783b0446a4e9ca6a12574a1471a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/42.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f103012f010d4c91852493b7a2f7023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/13.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e895e5d4c894aac9757dd0343e99f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493376cb00034611a3b163e2cf9ea03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15468 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5d3074d1844c96bdb56e8aa463e279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ee672a8d47450c9c88b0aa8919e4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset('khoadole/cars_8k_balance_dataset_full_augmented_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:04:32.703025Z",
     "iopub.status.busy": "2025-05-16T08:04:32.702729Z",
     "iopub.status.idle": "2025-05-16T08:04:32.707776Z",
     "shell.execute_reply": "2025-05-16T08:04:32.707037Z",
     "shell.execute_reply.started": "2025-05-16T08:04:32.703002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "color_list = ['blue', 'white', 'black', 'gray', 'silver']\n",
    "brand_list = ['bentley', 'audi', 'bmw', 'acura']\n",
    "\n",
    "def get_answer_type(answer):\n",
    "    if answer in color_list:\n",
    "        return 'color'\n",
    "    elif answer in brand_list:\n",
    "        return 'brand'\n",
    "    else:\n",
    "        return 'car_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:04:42.892205Z",
     "iopub.status.busy": "2025-05-16T08:04:42.891703Z",
     "iopub.status.idle": "2025-05-16T08:04:42.899194Z",
     "shell.execute_reply": "2025-05-16T08:04:42.898301Z",
     "shell.execute_reply.started": "2025-05-16T08:04:42.892183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, answer_to_idx):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.answer_to_idx = answer_to_idx\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        # Định nghĩa mapping cho answer_type\n",
    "        self.answer_type_map = {'color': 0, 'brand': 1, 'car_name': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        image_bytes = sample['image']['bytes']\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "        image_tensor = self.transform(image)\n",
    "        question = sample['question']\n",
    "        tokenized = self.tokenizer(question, padding='max_length', truncation=True, max_length=32, return_tensors='pt')\n",
    "        input_ids = tokenized['input_ids'].squeeze(0)\n",
    "        attention_mask = tokenized['attention_mask'].squeeze(0)\n",
    "        answer = sample['answer']\n",
    "        answer_idx = self.answer_to_idx.get(answer, -1)\n",
    "        answer_type = torch.tensor(self.answer_type_map[get_answer_type(answer)], dtype=torch.long)  # Chuyển thành tensor\n",
    "        return image_tensor, input_ids, attention_mask, answer_idx, answer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:08:33.976023Z",
     "iopub.status.busy": "2025-05-16T08:08:33.975454Z",
     "iopub.status.idle": "2025-05-16T08:08:33.982626Z",
     "shell.execute_reply": "2025-05-16T08:08:33.981846Z",
     "shell.execute_reply.started": "2025-05-16T08:08:33.975991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQAModel(nn.Module):\n",
    "    def __init__(self, num_answers):\n",
    "        super(VQAModel, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(768 * 2, 768),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, num_answers)\n",
    "        )\n",
    "        for param in self.bert.encoder.layer[:2].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.vit(image).last_hidden_state[:, 0, :]  # [batch, 768]\n",
    "        text_features = self.bert(input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]  # [batch, 768]\n",
    "        \n",
    "        # Gated fusion\n",
    "        combined_features = torch.cat([image_features, text_features], dim=1)  # [batch, 768*2]\n",
    "        gate = self.gate(combined_features)  # [batch, 768]\n",
    "        fused_features = gate * image_features + (1 - gate) * text_features  # [batch, 768]\n",
    "        \n",
    "        output = self.classifier(fused_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:08:35.333771Z",
     "iopub.status.busy": "2025-05-16T08:08:35.332988Z",
     "iopub.status.idle": "2025-05-16T08:08:37.041264Z",
     "shell.execute_reply": "2025-05-16T08:08:37.040576Z",
     "shell.execute_reply.started": "2025-05-16T08:08:35.333745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_31/1126064032.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "all_train_answers = list(set(sample['answer'] for sample in ds['train']))\n",
    "answer_to_idx = {answer: idx for idx, answer in enumerate(all_train_answers)}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = VQADataset(ds['train'], tokenizer, answer_to_idx)\n",
    "val_dataset = VQADataset(ds['validation'], tokenizer, answer_to_idx)\n",
    "test_dataset = VQADataset(ds['test'], tokenizer, answer_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Khởi tạo mô hình và tối ưu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VQAModel(num_answers=len(answer_to_idx)).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "scaler = GradScaler()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T08:08:42.337635Z",
     "iopub.status.busy": "2025-05-16T08:08:42.337333Z",
     "iopub.status.idle": "2025-05-16T09:46:27.443686Z",
     "shell.execute_reply": "2025-05-16T09:46:27.442053Z",
     "shell.execute_reply.started": "2025-05-16T08:08:42.337615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Training:   0%|          | 0/484 [00:00<?, ?it/s]/tmp/ipykernel_31/3882584153.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/30 - Training: 100%|██████████| 484/484 [03:15<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.7888\n",
      "Color Loss: 1.4489, Brand Loss: 1.4459, Car Name Loss: 2.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Validation:   0%|          | 0/151 [00:00<?, ?it/s]/tmp/ipykernel_31/3882584153.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy: 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.1078\n",
      "Color Loss: 1.0269, Brand Loss: 0.7525, Car Name Loss: 1.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy: 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Training: 100%|██████████| 484/484 [03:18<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.9350\n",
      "Color Loss: 0.8323, Brand Loss: 0.6978, Car Name Loss: 1.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.8088\n",
      "Color Loss: 0.7199, Brand Loss: 0.6734, Car Name Loss: 1.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.7275\n",
      "Color Loss: 0.6828, Brand Loss: 0.6583, Car Name Loss: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.6847\n",
      "Color Loss: 0.6636, Brand Loss: 0.6498, Car Name Loss: 0.7408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.6678\n",
      "Color Loss: 0.6603, Brand Loss: 0.6439, Car Name Loss: 0.6991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy: 0.8628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6553\n",
      "Color Loss: 0.6476, Brand Loss: 0.6405, Car Name Loss: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Training: 100%|██████████| 484/484 [03:18<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.6599\n",
      "Color Loss: 0.6469, Brand Loss: 0.6391, Car Name Loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy: 0.8653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6646\n",
      "Color Loss: 0.6676, Brand Loss: 0.6418, Car Name Loss: 0.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy: 0.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.6945\n",
      "Color Loss: 0.7009, Brand Loss: 0.6589, Car Name Loss: 0.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Validation Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.6601\n",
      "Color Loss: 0.6653, Brand Loss: 0.6496, Car Name Loss: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Validation Accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Training: 100%|██████████| 484/484 [03:15<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.6415\n",
      "Color Loss: 0.6389, Brand Loss: 0.6360, Car Name Loss: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Validation Accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.6404\n",
      "Color Loss: 0.6382, Brand Loss: 0.6353, Car Name Loss: 0.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Validation Accuracy: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.6388\n",
      "Color Loss: 0.6365, Brand Loss: 0.6341, Car Name Loss: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Validation Accuracy: 0.8694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.6380\n",
      "Color Loss: 0.6357, Brand Loss: 0.6336, Car Name Loss: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Validation Accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.6374\n",
      "Color Loss: 0.6359, Brand Loss: 0.6331, Car Name Loss: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Validation Accuracy: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.6365\n",
      "Color Loss: 0.6349, Brand Loss: 0.6323, Car Name Loss: 0.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Validation Accuracy: 0.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.6365\n",
      "Color Loss: 0.6355, Brand Loss: 0.6320, Car Name Loss: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Validation Accuracy: 0.8721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.6362\n",
      "Color Loss: 0.6349, Brand Loss: 0.6320, Car Name Loss: 0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Validation Accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.6356\n",
      "Color Loss: 0.6345, Brand Loss: 0.6316, Car Name Loss: 0.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Validation Accuracy: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.6358\n",
      "Color Loss: 0.6349, Brand Loss: 0.6316, Car Name Loss: 0.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Validation Accuracy: 0.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Training: 100%|██████████| 484/484 [03:16<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.6349\n",
      "Color Loss: 0.6337, Brand Loss: 0.6310, Car Name Loss: 0.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Validation Accuracy: 0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.6349\n",
      "Color Loss: 0.6343, Brand Loss: 0.6307, Car Name Loss: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Validation Accuracy: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Training: 100%|██████████| 484/484 [03:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.6346\n",
      "Color Loss: 0.6342, Brand Loss: 0.6303, Car Name Loss: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Validation Accuracy: 0.8789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Training: 100%|██████████| 484/484 [03:18<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.6343\n",
      "Color Loss: 0.6339, Brand Loss: 0.6302, Car Name Loss: 0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - Validation: 100%|██████████| 151/151 [00:18<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Validation Accuracy: 0.8754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - Training:  10%|▉         | 47/484 [00:19<03:02,  2.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3882584153.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mweighted_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/41707257.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [batch, 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [batch, 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool_masked_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m    122\u001b[0m     ) -> torch.Tensor:\n\u001b[1;32m    123\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbool_masked_pos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;34mf\" ({self.image_size[0]}*{self.image_size[1]}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 )\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "best_val_acc = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "color_loss_weight = 2.0\n",
    "answer_type_map_reverse = {0: 'color', 1: 'brand', 2: 'car_name'}  # Để map ngược lại từ số sang string\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_color_loss = 0\n",
    "    total_brand_loss = 0\n",
    "    total_car_name_loss = 0\n",
    "    color_count = 0\n",
    "    brand_count = 0\n",
    "    car_name_count = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        image, input_ids, attention_mask, answer_idx, answer_type = [x.to(device) for x in batch]\n",
    "        valid_mask = answer_idx != -1\n",
    "        if not valid_mask.any():\n",
    "            continue\n",
    "        # Lọc các tensor bằng valid_mask\n",
    "        image = image[valid_mask]\n",
    "        input_ids = input_ids[valid_mask]\n",
    "        attention_mask = attention_mask[valid_mask]\n",
    "        answer_idx = answer_idx[valid_mask]\n",
    "        answer_type = answer_type[valid_mask]  # answer_type giờ là tensor\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(image, input_ids, attention_mask)\n",
    "            loss = loss_fn(output, answer_idx)\n",
    "            weighted_loss = torch.zeros_like(loss)\n",
    "            for i in range(len(answer_type)):\n",
    "                ans_type_str = answer_type_map_reverse[answer_type[i].item()]  # Map ngược lại thành string\n",
    "                if ans_type_str == 'color':\n",
    "                    weighted_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)) * color_loss_weight\n",
    "                    total_color_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                    color_count += 1\n",
    "                elif ans_type_str == 'brand':\n",
    "                    weighted_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0))\n",
    "                    total_brand_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                    brand_count += 1\n",
    "                else:\n",
    "                    weighted_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0))\n",
    "                    total_car_name_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                    car_name_count += 1\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_color_loss = total_color_loss / color_count if color_count > 0 else 0\n",
    "    avg_brand_loss = total_brand_loss / brand_count if brand_count > 0 else 0\n",
    "    avg_car_name_loss = total_car_name_loss / car_name_count if car_name_count > 0 else 0\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Color Loss: {avg_color_loss:.4f}, Brand Loss: {avg_brand_loss:.4f}, Car Name Loss: {avg_car_name_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            image, input_ids, attention_mask, answer_idx, _ = [x.to(device) for x in batch]\n",
    "            valid_mask = answer_idx != -1\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "            image = image[valid_mask]\n",
    "            input_ids = input_ids[valid_mask]\n",
    "            attention_mask = attention_mask[valid_mask]\n",
    "            answer_idx = answer_idx[valid_mask]\n",
    "            with autocast():\n",
    "                output = model(image, input_ids, attention_mask)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == answer_idx).sum().item()\n",
    "            total += answer_idx.size(0)\n",
    "    val_accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    scheduler.step(val_accuracy)\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_vqa_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T09:46:30.869286Z",
     "iopub.status.busy": "2025-05-16T09:46:30.868966Z",
     "iopub.status.idle": "2025-05-16T09:46:52.202614Z",
     "shell.execute_reply": "2025-05-16T09:46:52.201536Z",
     "shell.execute_reply.started": "2025-05-16T09:46:30.869260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/162 [00:00<?, ?it/s]/tmp/ipykernel_31/2637264605.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Test: 100%|██████████| 162/162 [00:20<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Total Accuracy: 0.8576\n",
      "Test Color Accuracy: 0.8423, Brand Accuracy: 0.9476, Car Name Accuracy: 0.7829\n",
      "Test Color Loss: 1.1505, Brand Loss: 0.7713, Car Name Loss: 1.2820\n",
      "\n",
      "Top 4 màu sai nhiều nhất:\n",
      "- gray: 0.2735 (27.35%), xuất hiện 245 lần\n",
      "  Nhầm lẫn với:\n",
      "    + white: 10 lần\n",
      "    + black: 31 lần\n",
      "    + silver: 26 lần\n",
      "- silver: 0.2500 (25.00%), xuất hiện 248 lần\n",
      "  Nhầm lẫn với:\n",
      "    + white: 23 lần\n",
      "    + gray: 18 lần\n",
      "    + blue: 8 lần\n",
      "    + black: 13 lần\n",
      "- blue: 0.1386 (13.86%), xuất hiện 339 lần\n",
      "  Nhầm lẫn với:\n",
      "    + silver: 17 lần\n",
      "    + black: 27 lần\n",
      "    + gray: 1 lần\n",
      "    + white: 2 lần\n",
      "- black: 0.1304 (13.04%), xuất hiện 368 lần\n",
      "  Nhầm lẫn với:\n",
      "    + white: 27 lần\n",
      "    + silver: 6 lần\n",
      "    + gray: 13 lần\n",
      "    + blue: 2 lần\n",
      "\n",
      "Top 4 hãng xe sai nhiều nhất:\n",
      "- bmw: 0.0659 (6.59%), xuất hiện 425 lần\n",
      "  Nhầm lẫn với:\n",
      "    + bentley: 3 lần\n",
      "    + audi: 22 lần\n",
      "    + acura: 3 lần\n",
      "- audi: 0.0611 (6.11%), xuất hiện 442 lần\n",
      "  Nhầm lẫn với:\n",
      "    + bmw: 13 lần\n",
      "    + bentley: 6 lần\n",
      "    + acura: 8 lần\n",
      "- acura: 0.0539 (5.39%), xuất hiện 371 lần\n",
      "  Nhầm lẫn với:\n",
      "    + bmw: 7 lần\n",
      "    + audi: 9 lần\n",
      "    + bentley: 4 lần\n",
      "- bentley: 0.0312 (3.12%), xuất hiện 480 lần\n",
      "  Nhầm lẫn với:\n",
      "    + audi: 13 lần\n",
      "    + bmw: 1 lần\n",
      "    + acura: 1 lần\n",
      "\n",
      "Top 4 tên xe sai nhiều nhất:\n",
      "- Bentley Mulsanne: 0.9300 (93.00%), xuất hiện 100 lần\n",
      "  Nhầm lẫn với:\n",
      "    + Bentley Continental: 13 lần\n",
      "    + Bentley Flying: 50 lần\n",
      "    + Bentley Bentayga: 30 lần\n",
      "- BMW 330: 0.4100 (41.00%), xuất hiện 100 lần\n",
      "  Nhầm lẫn với:\n",
      "    + BMW X5: 2 lần\n",
      "    + Audi A4: 35 lần\n",
      "    + BMW X3: 1 lần\n",
      "    + Acura TLX: 1 lần\n",
      "    + BMW X1: 2 lần\n",
      "- BMW X1: 0.3810 (38.10%), xuất hiện 42 lần\n",
      "  Nhầm lẫn với:\n",
      "    + BMW X3: 7 lần\n",
      "    + BMW X5: 8 lần\n",
      "    + Acura RDX: 1 lần\n",
      "- Audi A4: 0.3500 (35.00%), xuất hiện 100 lần\n",
      "  Nhầm lẫn với:\n",
      "    + BMW 330: 4 lần\n",
      "    + Audi Q5: 3 lần\n",
      "    + Audi Q3: 18 lần\n",
      "    + Bentley Flying: 1 lần\n",
      "    + Bentley Continental: 4 lần\n",
      "    + Audi Q7: 2 lần\n",
      "    + Acura TLX: 3 lần\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# Test\n",
    "model.load_state_dict(torch.load('best_vqa_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "correct_color = 0\n",
    "total_color = 0\n",
    "correct_brand = 0\n",
    "total_brand = 0\n",
    "correct_car_name = 0\n",
    "total_car_name = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_color_loss = 0\n",
    "total_brand_loss = 0\n",
    "total_car_name_loss = 0\n",
    "color_count = 0\n",
    "brand_count = 0\n",
    "car_name_count = 0\n",
    "answer_type_map_reverse = {0: 'color', 1: 'brand', 2: 'car_name'}\n",
    "idx_to_answer = {idx: answer for answer, idx in answer_to_idx.items()}  # Map ngược từ idx sang answer\n",
    "\n",
    "# Theo dõi số lần xuất hiện, đúng, và nhầm lẫn\n",
    "color_stats = defaultdict(lambda: {'correct': 0, 'total': 0, 'confusion': defaultdict(int)})\n",
    "brand_stats = defaultdict(lambda: {'correct': 0, 'total': 0, 'confusion': defaultdict(int)})\n",
    "car_name_stats = defaultdict(lambda: {'correct': 0, 'total': 0, 'confusion': defaultdict(int)})\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test\"):\n",
    "        image, input_ids, attention_mask, answer_idx, answer_type = [x.to(device) for x in batch]\n",
    "        valid_mask = (answer_idx != -1).to(device)\n",
    "        if not valid_mask.any():\n",
    "            continue\n",
    "        image = image[valid_mask]\n",
    "        input_ids = input_ids[valid_mask]\n",
    "        attention_mask = attention_mask[valid_mask]\n",
    "        answer_idx = answer_idx[valid_mask]\n",
    "        answer_type = answer_type[valid_mask]\n",
    "\n",
    "        with autocast():\n",
    "            output = model(image, input_ids, attention_mask)\n",
    "            loss = loss_fn(output, answer_idx)\n",
    "        pred = output.argmax(dim=1)\n",
    "        total_correct += (pred == answer_idx).sum().item()\n",
    "        total_samples += answer_idx.size(0)\n",
    "\n",
    "        for i in range(len(answer_type)):\n",
    "            ans_type_str = answer_type_map_reverse[answer_type[i].item()]\n",
    "            true_answer = idx_to_answer[answer_idx[i].item()]\n",
    "            pred_answer = idx_to_answer[pred[i].item()]\n",
    "            is_correct = pred[i] == answer_idx[i]\n",
    "\n",
    "            if ans_type_str == 'color':\n",
    "                total_color += 1\n",
    "                total_color_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                color_count += 1\n",
    "                if is_correct:\n",
    "                    correct_color += 1\n",
    "                color_stats[true_answer]['total'] += 1\n",
    "                if is_correct:\n",
    "                    color_stats[true_answer]['correct'] += 1\n",
    "                else:\n",
    "                    color_stats[true_answer]['confusion'][pred_answer] += 1\n",
    "\n",
    "            elif ans_type_str == 'brand':\n",
    "                total_brand += 1\n",
    "                total_brand_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                brand_count += 1\n",
    "                if is_correct:\n",
    "                    correct_brand += 1\n",
    "                brand_stats[true_answer]['total'] += 1\n",
    "                if is_correct:\n",
    "                    brand_stats[true_answer]['correct'] += 1\n",
    "                else:\n",
    "                    brand_stats[true_answer]['confusion'][pred_answer] += 1\n",
    "\n",
    "            else:\n",
    "                total_car_name += 1\n",
    "                total_car_name_loss += loss_fn(output[i].unsqueeze(0), answer_idx[i].unsqueeze(0)).item()\n",
    "                car_name_count += 1\n",
    "                if is_correct:\n",
    "                    correct_car_name += 1\n",
    "                car_name_stats[true_answer]['total'] += 1\n",
    "                if is_correct:\n",
    "                    car_name_stats[true_answer]['correct'] += 1\n",
    "                else:\n",
    "                    car_name_stats[true_answer]['confusion'][pred_answer] += 1\n",
    "\n",
    "# Tính accuracy tổng và riêng\n",
    "test_color_accuracy = correct_color / total_color if total_color > 0 else 0\n",
    "test_brand_accuracy = correct_brand / total_brand if total_brand > 0 else 0\n",
    "test_car_name_accuracy = correct_car_name / total_car_name if total_car_name > 0 else 0\n",
    "test_total_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "avg_color_loss = total_color_loss / color_count if color_count > 0 else 0\n",
    "avg_brand_loss = total_brand_loss / brand_count if brand_count > 0 else 0\n",
    "avg_car_name_loss = total_car_name_loss / car_name_count if car_name_count > 0 else 0\n",
    "\n",
    "# Tính top 4 sai nhiều nhất và nhầm lẫn\n",
    "def get_top_errors(stats, category_name):\n",
    "    error_rates = []\n",
    "    for answer, stat in stats.items():\n",
    "        total = stat['total']\n",
    "        correct = stat['correct']\n",
    "        if total > 0:\n",
    "            error_rate = 1 - (correct / total)\n",
    "            error_rates.append((answer, error_rate, total, stat['confusion']))\n",
    "    error_rates.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    top_4 = error_rates[:4]\n",
    "    print(f\"\\nTop 4 {category_name} sai nhiều nhất:\")\n",
    "    for answer, error_rate, total, confusion in top_4:\n",
    "        print(f\"- {answer}: {error_rate:.4f} ({(error_rate * 100):.2f}%), xuất hiện {total} lần\")\n",
    "        print(f\"  Nhầm lẫn với:\")\n",
    "        for pred_answer, count in confusion.items():\n",
    "            print(f\"    + {pred_answer}: {count} lần\")\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Test Total Accuracy: {test_total_accuracy:.4f}\")\n",
    "print(f\"Test Color Accuracy: {test_color_accuracy:.4f}, Brand Accuracy: {test_brand_accuracy:.4f}, Car Name Accuracy: {test_car_name_accuracy:.4f}\")\n",
    "print(f\"Test Color Loss: {avg_color_loss:.4f}, Brand Loss: {avg_brand_loss:.4f}, Car Name Loss: {avg_car_name_loss:.4f}\")\n",
    "\n",
    "get_top_errors(color_stats, \"màu\")\n",
    "get_top_errors(brand_stats, \"hãng xe\")\n",
    "get_top_errors(car_name_stats, \"tên xe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T09:47:21.593746Z",
     "iopub.status.busy": "2025-05-16T09:47:21.592990Z",
     "iopub.status.idle": "2025-05-16T09:47:22.698979Z",
     "shell.execute_reply": "2025-05-16T09:47:22.698175Z",
     "shell.execute_reply.started": "2025-05-16T09:47:21.593716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_path = \"/kaggle/working/my-vqa-model\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "torch.save(model.state_dict(), f\"{save_path}/pytorch_model.bin\")\n",
    "config = {\n",
    "    \"vit_model\": \"google/vit-base-patch16-224\",\n",
    "    \"bert_model\": \"bert-base-uncased\",\n",
    "    \"num_answers\": len(answer_to_idx),\n",
    "    \"architecture\": \"ViT+BERT gated fusion\"\n",
    "}\n",
    "with open(f\"{save_path}/config.json\", \"w\") as f:\n",
    "    json.dump(config, f)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "with open(f\"{save_path}/answer_list.json\", \"w\") as f:\n",
    "    json.dump(all_train_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
